{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group name: Explanation is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Text Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to explain the prediction of a text classifier, detecting which part of the input text is responsible of a given prediction. For that we used SST-2 (Stanford Sentiment Treebank 2) dataset which consists of text and sentiment label pairs where the label 0 indicates negative sentiment 1 indicates positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import string \n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from load_glove import load_file, construct_embedding\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "We used SST-2, a sentiment anlysis dataset which contains thousands of text/sentiment pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\urchade\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    }
   ],
   "source": [
    "sst2_dataset = datasets.load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sst2_dataset['train']['label']\n",
    "texts = sst2_dataset['train']['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 29780 negative texts and 37569 positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 29780, 1: 37569})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    \"\"\"Tokenize a text by removing punctuation\"\"\"\n",
    "    \n",
    "    text = text.lower().split()\n",
    "        \n",
    "    return [t.strip(string.punctuation) for t in text if t not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'happy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization example\n",
    "\n",
    "tokenize('I/ am happy , .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 27205), ('a', 21609), ('and', 19920), ('of', 17907), ('to', 12538)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### List of all tokens from the dataset\n",
    "all_tokens = [tokens for sent in texts for tokens in tokenize(sent)]\n",
    "\n",
    "# count tokens\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "# The most common words are the, a, and ... etc\n",
    "token_counts.most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'and', 'of', 'to', 's', 'is', 'that', 'in', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Here we create our vocabulary\n",
    "\n",
    "min_freq = 3\n",
    "\n",
    "vocab = [a[0] for a in list(filter(lambda x: x[1] >= min_freq, token_counts.most_common()))]\n",
    "\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[UNK]', 'the', 'a', 'and']\n"
     ]
    }
   ],
   "source": [
    "# Add a padding token and a UNK token to our vocabulary\n",
    "\n",
    "pad_token = '[PAD]'\n",
    "unk_token = '[UNK]'\n",
    "\n",
    "vocab.insert(0, pad_token)\n",
    "vocab.insert(1, unk_token)\n",
    "\n",
    "print(vocab[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man => 206\n"
     ]
    }
   ],
   "source": [
    "id2word = dict(enumerate(vocab)) # a dict that map an Id to a word\n",
    "word2id = {v:k for (k, v) in id2word.items()} # inverse mapping\n",
    "\n",
    "print(f\"man => {word2id['man']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is 13481 unique tokens in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "print(f'there is {len(vocab)} unique tokens in the vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to sequence of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the movie was great == > [2, 19, 93, 96]\n"
     ]
    }
   ],
   "source": [
    "def sent2ids(text: str):\n",
    "    \"\"\"Convert a text to a sequence of IDs\"\"\"\n",
    "    sent = []\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "    \n",
    "    for word in tokens:\n",
    "        \n",
    "        try:\n",
    "            id_w = word2id[word]\n",
    "            \n",
    "        except KeyError:\n",
    "            id_w = word2id['[UNK]']\n",
    "        \n",
    "        sent.append(id_w)\n",
    "        \n",
    "    return sent\n",
    "\n",
    "# Example\n",
    "\n",
    "s = 'the movie was great'\n",
    "print(f\"{s} == > {sent2ids(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 400000/400000 [00:42<00:00, 9463.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 13481/13481 [00:00<00:00, 300377.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded = 12564/13481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optionnal: Use pretrained word vectors for better classification results\n",
    "\n",
    "glove_embedding = None\n",
    "use_glove = True \n",
    "\n",
    "glove_file = 'glove.6B.50d.txt' # download from http://nlp.stanford.edu/data/glove.6B.zip\n",
    "vect_dim = 50\n",
    "\n",
    "if use_glove:\n",
    "    \n",
    "    # load glove\n",
    "    glove_vec = load_file(glove_file)\n",
    "    \n",
    "    # construct the embedding matrix given id2word\n",
    "    glove_embedding = construct_embedding(glove_vec, id2word, dim=vect_dim)\n",
    "    \n",
    "    # convert the embedding matrix to torch tensor\n",
    "    glove_embedding = torch.Tensor(glove_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts: list, labels: list):\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = sent2ids(self.texts[idx])\n",
    "        \n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        # handle empty text\n",
    "        if len(x) == 0:\n",
    "            return self.__getitem__(np.random.randint(0, len(self)))\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(sequence_list, max_seq):\n",
    "    \n",
    "    \"\"\"Padding/Truncate a list of sequences to max_seq\"\"\"\n",
    "    \n",
    "    max_batch = max([s.shape[0] for s in sequence_list])\n",
    "    \n",
    "    result = np.zeros((len(sequence_list), max_batch))\n",
    "    \n",
    "    for i in range(len(sequence_list)):\n",
    "        \n",
    "        array_i = sequence_list[i]\n",
    "\n",
    "        dim_1 = array_i.shape[0]\n",
    "        \n",
    "        result[i, :dim_1] += array_i\n",
    "        \n",
    "    if max_batch > max_seq:\n",
    "        result = result[:, :max_seq]\n",
    "    \n",
    "    return torch.LongTensor(result)\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "        \n",
    "    src = pad_seq([np.array(item[0]) for item in batch], max_seq=50)\n",
    "        \n",
    "    y = torch.FloatTensor([item[1] for item in batch])\n",
    "        \n",
    "    return [src, y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_bs': 1024,\n",
    "    'val_bs': 128,\n",
    "    'val_size': 5000,\n",
    "}\n",
    "\n",
    "\n",
    "dataset = TextDataset(texts, labels)\n",
    "\n",
    "train, val = random_split(dataset, [len(dataset)-config['val_size'], config['val_size']])\n",
    "\n",
    "loader = DataLoader(train, config['train_bs'], True, collate_fn=collate, drop_last=True)\n",
    "\n",
    "val_load = DataLoader(val, config['val_bs'], False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple encoder: Embedding layer + mlp\n",
    "\n",
    "class SimpleEncoder(nn.Module):    \n",
    "    def __init__(self, n_words: int, emb_dim: int, hidden_dim: int, embedding_weight: torch.Tensor=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(n_words, emb_dim, padding_idx=0, _weight=embedding_weight)\n",
    "        \n",
    "        # Multi-Layer Perceptron\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        x: input IDs of shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "                \n",
    "        out = self.embedding(x) # [batch_size, seq_len, emb_dim]\n",
    "        \n",
    "        return self.mlp(out) # [batch_size, seq_len, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN encoder: Embedding layer + Bi-LSTM\n",
    "\n",
    "class RnnEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_words: int, emb_dim: int, hidden_dim: int, embedding_weight: torch.Tensor=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(n_words, emb_dim, padding_idx=0, _weight=embedding_weight)\n",
    "        \n",
    "        # Bi-LSTM Layer\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Projection\n",
    "        self.W = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "    def forward(self, x: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        x: input IDs of shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        \n",
    "        bs, max_len = x.size()\n",
    "        \n",
    "        lens = (x != 0).sum(1).cpu()\n",
    "                \n",
    "        embs = self.embedding(x) # [batch_size, seq_len, emb_dim]\n",
    "            \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embs, lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        out_packed, *_ = self.rnn(packed)\n",
    "        \n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        \n",
    "        return self.W(unpacked) # [batch_size, seq_len, hidden_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer\n",
    "\n",
    "We employ the scaled dot product attention (Vaswani et al., 2017):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dot_prod_att.PNG\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layer\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        \n",
    "        # Parameter: Query vector \n",
    "        self.query = nn.Parameter(data=torch.randn(1, self.dim))\n",
    "        \n",
    "        # Key Linear Transform\n",
    "        self.Wk = nn.Linear(self.dim, self.dim, bias=False)\n",
    "        \n",
    "        # Value Linear Transform\n",
    "        self.Wv = nn.Linear(self.dim, self.dim, bias=False)\n",
    "        \n",
    "    def forward(self, hidden: torch.Tensor, mask: torch.BoolTensor=None):\n",
    "        \"\"\"\n",
    "        hidden: Tokens representations of shape [batch_size, seq_len, dim]\n",
    "        mask: Attention mask of shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        \n",
    "        bs, *_ = hidden.size()\n",
    "        \n",
    "        # key tensor\n",
    "        key = self.Wk(hidden) # [batch_size, seq_len, dim]\n",
    "        \n",
    "        # value\n",
    "        value = self.Wv(hidden) # [batch_size, seq_len, dim]\n",
    "        \n",
    "        # query\n",
    "        query = self.query.expand(bs, self.dim).reshape(bs, self.dim, 1) # [batch_size, dim, 1]\n",
    "        \n",
    "        score = torch.bmm(key, query) # [batch_size, seq_len, 1]\n",
    "        \n",
    "        score /= np.sqrt(self.dim) # scale \n",
    "        \n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask.reshape(score.shape), float('-inf'))\n",
    "            \n",
    "        attention = torch.softmax(score, dim = 1) # [batch_size, seq_len, 1]\n",
    "        \n",
    "        output = attention * value # [batch_size, seq_len, dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text classifier: Encoder + Attention Layer + Fully connected Layers\n",
    "\n",
    "class AttentionClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_words: int, emb_dim: int, hidden_dim: int, encoder: str='simple', embedding_weight: torch.Tensor=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if encoder == 'rnn':\n",
    "            self.encode = RnnEncoder(n_words, emb_dim, hidden_dim, embedding_weight)\n",
    "        elif encoder == 'simple':\n",
    "            self.encode = SimpleEncoder(n_words, emb_dim, hidden_dim, embedding_weight)\n",
    "        \n",
    "        self.attention_layer = DotProductAttention(hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x: Input Ids of shape [batch_size, seq_len]\n",
    "        mask: Attention mask of shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        \n",
    "        encoded_sequence = self.encode(x) # [batch_size, hidden_dim]\n",
    "        \n",
    "        out, attention_score = self.attention_layer(encoded_sequence, mask)\n",
    "        \n",
    "        out = out.mean(1) # [batch_size, hidden_dim]\n",
    "        \n",
    "        y = self.fc(out) # [batch_size, 1]\n",
    "        \n",
    "        return y, attention_score # output the prediction and attention weight\n",
    "    \n",
    "    def compute_loss(self, x: torch.LongTensor, y: torch.FloatTensor, mask: torch.BoolTensor=None):\n",
    "        \"\"\"\n",
    "        Compute the binary cross-entropy loss\n",
    "        \n",
    "        x: Input Ids of shape [batch_size, seq_len]\n",
    "        y: Labels of shape [batch_size]\n",
    "        mask: Attention mask of shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        y_, attention_score = self.forward(x, mask)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(y_.squeeze(), y)\n",
    "        \n",
    "        return loss, self.accuracy(y_, y) # return the loss and accuracy\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def accuracy(self, y_, y):\n",
    "        \n",
    "        y_ = (y_.squeeze() > 0.5).float()\n",
    "        \n",
    "        return (y == y_).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is similar to this one from (Wiegreffe and Pinter, 2019):\n",
    "\n",
    "  <img src=\"images/model.PNG\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "model = AttentionClassifier(n_words=len(vocab), emb_dim=50, hidden_dim=64,\n",
    "                           encoder='simple',\n",
    "                           embedding_weight=glove_embedding).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 || Train_loss =  0.580 || Train_acc =  0.545 || Valid_acc =  0.000: : 60it [00:06,  9.37it/s]\n",
      "1 || Train_loss =  0.380 || Train_acc =  0.811 || Valid_acc =  0.717: : 60it [00:05, 10.97it/s]\n",
      "2 || Train_loss =  0.252 || Train_acc =  0.877 || Valid_acc =  0.859: : 60it [00:04, 12.91it/s]\n",
      "3 || Train_loss =  0.252 || Train_acc =  0.904 || Valid_acc =  0.891: : 60it [00:04, 12.67it/s]\n",
      "4 || Train_loss =  0.193 || Train_acc =  0.92 || Valid_acc =  0.892: : 60it [00:04, 13.04it/s] \n",
      "5 || Train_loss =  0.172 || Train_acc =  0.931 || Valid_acc =  0.912: : 60it [00:05, 11.38it/s]\n",
      "6 || Train_loss =  0.149 || Train_acc =  0.938 || Valid_acc =  0.915: : 60it [00:05, 11.93it/s]\n",
      "7 || Train_loss =  0.154 || Train_acc =  0.943 || Valid_acc =  0.917: : 60it [00:04, 12.38it/s]\n",
      "8 || Train_loss =  0.118 || Train_acc =  0.949 || Valid_acc =  0.919: : 60it [00:04, 12.50it/s]\n",
      "9 || Train_loss =  0.120 || Train_acc =  0.952 || Valid_acc =  0.918: : 60it [00:04, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final validation accuracy =  0.920\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "val_acc_ = [0]\n",
    "\n",
    "for ep in range(n_epochs):\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader), leave=None)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    acc_ = []\n",
    "    \n",
    "    for i, (x, y) in pbar:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        m = x==0\n",
    "        \n",
    "        x, y, m = x.to(device), y.to(device), m.to(device)\n",
    "\n",
    "        loss, acc = model.compute_loss(x, y, m)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc_.append(acc.item())\n",
    "        \n",
    "        pbar.set_description(f\"{ep} || Train_loss = {loss.item(): .3f} || Train_acc = {np.array(acc_).mean(): .3} || Valid_acc = {np.array(val_acc_).mean(): .3f}\")\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        val_acc_ = []\n",
    "        \n",
    "        for x, y in val_load:\n",
    "            \n",
    "            m = x==0\n",
    "            \n",
    "            x, y, m = x.to(device), y.to(device), m.to(device)\n",
    "\n",
    "            loss, acc = model.compute_loss(x, y, m)\n",
    "            \n",
    "            val_acc_.append(acc.item())\n",
    "        \n",
    "        if ep == n_epochs-1:\n",
    "            print(f\"Final validation accuracy = {np.array(val_acc_).mean(): .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode !\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cpu()\n",
    "print('Evaluation mode !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor = tensor([[  51, 1089,   20,   19]]) \n",
      "tokens = ['i', 'hate', 'this', 'movie']\n",
      "attention_score = [0.03606517 0.9513782  0.00638908 0.00616754] \n",
      "prediction = 1.260003756644323e-20\n"
     ]
    }
   ],
   "source": [
    "def transform_text(text: str):\n",
    "    \n",
    "    sequence = sent2ids(text.lower())\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for word_id in sequence:\n",
    "        \n",
    "        word = id2word[word_id]\n",
    "        \n",
    "        tokens.append(word)\n",
    "        \n",
    "    x = torch.LongTensor(sequence).reshape(1, -1) # convert to torch\n",
    "    \n",
    "    return x, tokens\n",
    "\n",
    "tensor, tokens = transform_text('i hate this movie')\n",
    "\n",
    "print(f'tensor = {tensor} \\ntokens = {tokens}')\n",
    "\n",
    "\n",
    "# This function returns the prediction and the attention weigths given a sequence\n",
    "@torch.no_grad()\n",
    "def predict(sequence: torch.LongTensor, model: nn.Module):\n",
    "    \n",
    "    pred, attention = model(sequence)\n",
    "    \n",
    "    return pred.item(), attention.squeeze().numpy()\n",
    "\n",
    "prediction, attention_score = predict(tensor, model)\n",
    "\n",
    "print(f'attention_score = {attention_score} \\nprediction = {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-based explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first approach is to explain our model prediction using the attention score produced by the model's attention module. The intuition is that the model will focus on the most important words in order to make his prediction. This approach is widely used in the Deep Learning literature, for example in Neural Machine Translation (Bahdanau et al., 2015) or Natural Language Inference (Parikh et al., 2016). However, the use of attention for explaining Deep Learning models remains controversial (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019).\n",
    "\n",
    "* Attention is not explanation (Jain and Wallace, 2019)\n",
    "* Attention is not not explanation (Wiegreffe and Pinter, 2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention for Neural Machine Translation: Image from Bahdanau et al. (2015)\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/bahdanau.PNG\" width=\"300\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hohman et al.'s human-centered interrogative framework**:\n",
    "\n",
    "    - Why:\n",
    "        - Interpretability and explainability\n",
    "        - Detecting bias in the dataset/model\n",
    "\n",
    "    - What:\n",
    "        - The attention weights\n",
    "\n",
    "    - When:\n",
    "        - After training\n",
    "\n",
    "    - Who:\n",
    "        - Model developers\n",
    "        - Model Users\n",
    "        - Non-experts\n",
    "\n",
    "    - How:\n",
    "        - Visualize feature importance using saliency maps\n",
    "        \n",
    "    - Where:\n",
    "        - Application domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact(text='the movie is not bad')\n",
    "def explain_with_attention(text: str):\n",
    "    \n",
    "    model.cpu()\n",
    "    model.eval() # eval mode\n",
    "            \n",
    "    seq_torch, word_sequence = transform_text(text)\n",
    "    \n",
    "    pred, attention = predict(seq_torch, model) # prediction + attention weights\n",
    "\n",
    "    heatmap = pd.DataFrame(data = attention.reshape(1, -1), columns=word_sequence)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    \n",
    "    sns.heatmap(heatmap, annot=True, yticklabels=False, cmap='Reds')\n",
    "    \n",
    "    if pred > 0.5:\n",
    "        print(f'positive => {pred: 0.3f}')\n",
    "    \n",
    "    else:\n",
    "        print(f'negative => {pred: 0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive =>  1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_with_attention('the movie is good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we extract positive/negative words from the validation dataset\n",
    "# => take the words that has gotten the most attention during a forward pass to model\n",
    "\n",
    "confidence = 0.9999\n",
    "\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for x, y in val_load:\n",
    "\n",
    "        m = x==0 # mask\n",
    "        y_hat, attention_score = model.forward(x, m)\n",
    "        \n",
    "        att_word = torch.argmax(attention_score.squeeze(), dim=1)\n",
    "        \n",
    "        for a, w, yy in zip(att_word, x, y_hat):\n",
    "            \n",
    "            if yy > confidence:\n",
    "                positive_words.append(id2word[w[a].item()])\n",
    "                \n",
    "            elif yy < 1 - confidence:\n",
    "                negative_words.append(id2word[w[a].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### positive words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sustains',\n",
       " 'inimitable',\n",
       " 'penetrating',\n",
       " 'playful',\n",
       " 'admirable',\n",
       " 'sought',\n",
       " 'sweet',\n",
       " 'fantasy',\n",
       " 'continues',\n",
       " 'astonishing',\n",
       " 'broadway',\n",
       " 'engage',\n",
       " 'significant',\n",
       " 'feat',\n",
       " 'draws',\n",
       " 'exhilarating',\n",
       " 'collectively',\n",
       " 'pearls',\n",
       " 'panache',\n",
       " 'valiant',\n",
       " 'monumental',\n",
       " 'exotic',\n",
       " 'intelligently',\n",
       " 'distinctive',\n",
       " 'innovators',\n",
       " 'welcome',\n",
       " 'strategies',\n",
       " 'tasteful',\n",
       " 'laughter',\n",
       " 'charismatic',\n",
       " 'clever',\n",
       " 'manages',\n",
       " 'superior',\n",
       " 'craftsmanship',\n",
       " 'gorgeously',\n",
       " 'tour',\n",
       " 'challenges',\n",
       " 'undoubtedly',\n",
       " 'right',\n",
       " 'hopeful',\n",
       " 'recovery',\n",
       " 'anchoring',\n",
       " 'beautifully',\n",
       " 'professionals',\n",
       " 'fun',\n",
       " 'creates',\n",
       " 'thought-provoking',\n",
       " 'lyrical',\n",
       " 'transcendence',\n",
       " 'portrayal',\n",
       " 'elusive',\n",
       " 'incredible',\n",
       " 'companionship',\n",
       " 'a-list',\n",
       " 'edge',\n",
       " 'stagings',\n",
       " 'charisma',\n",
       " 'fearlessness',\n",
       " 'techniques',\n",
       " 'exciting',\n",
       " 'acclaim',\n",
       " 'thoughtful',\n",
       " 'goofily',\n",
       " 'heartfelt',\n",
       " 'distinguished',\n",
       " 'pretty',\n",
       " 'entertaining',\n",
       " 'sights',\n",
       " 'righteousness',\n",
       " 'salton',\n",
       " 'love',\n",
       " 'sweetly',\n",
       " 'production',\n",
       " 'works',\n",
       " 'oddly',\n",
       " 'crafty',\n",
       " 'achievements',\n",
       " 'merits',\n",
       " 'smoothly',\n",
       " 'choreography',\n",
       " 'ages',\n",
       " 'eager',\n",
       " 'grandeur',\n",
       " 'breadth',\n",
       " 'gem',\n",
       " 'quirkily',\n",
       " 'yarn',\n",
       " 'instructive',\n",
       " 'handsome',\n",
       " 'feel-good',\n",
       " 'wry',\n",
       " 'optimism',\n",
       " 'high-octane',\n",
       " 'jia',\n",
       " 'commanding',\n",
       " 'well',\n",
       " 'anchor',\n",
       " 'striking',\n",
       " 'revel',\n",
       " 'serene',\n",
       " 'companionable',\n",
       " 'glorious',\n",
       " 'holly',\n",
       " 'explore',\n",
       " 'pleasing',\n",
       " 'proud',\n",
       " 'modest',\n",
       " 'bliss',\n",
       " 'sisters',\n",
       " 'funny',\n",
       " 'bravery',\n",
       " 'elegance',\n",
       " 'splendid',\n",
       " 'engaging',\n",
       " 'scenery',\n",
       " 'sincere',\n",
       " 'wonders',\n",
       " 'meditation',\n",
       " 'yearnings',\n",
       " 'nice',\n",
       " 'important',\n",
       " 'stars',\n",
       " 'wickedly',\n",
       " 'genuine',\n",
       " 'above-average',\n",
       " 'impeccable',\n",
       " 'high-concept',\n",
       " 'simplicity',\n",
       " 'earnest',\n",
       " 'meaningful',\n",
       " 'paxton',\n",
       " 'best',\n",
       " 'chinese',\n",
       " 'riveting',\n",
       " 'consistently',\n",
       " 'perfect',\n",
       " 'diamond',\n",
       " 'warm',\n",
       " 'polished',\n",
       " 'laughs',\n",
       " 'family',\n",
       " 'next',\n",
       " 'professional',\n",
       " 'vividly',\n",
       " 'exceptional',\n",
       " 'motivate',\n",
       " 'rich',\n",
       " 'confidence',\n",
       " 'hearts',\n",
       " 'friendship',\n",
       " 'stylized',\n",
       " 'deliciously',\n",
       " 'vintage',\n",
       " 'charming',\n",
       " 'suspenseful',\n",
       " 'attractive',\n",
       " 'suitable',\n",
       " 'enjoyed',\n",
       " 'rarest',\n",
       " 'delivers',\n",
       " 'writer/director',\n",
       " 'jaw-dropping',\n",
       " 'wiseman',\n",
       " 'quietly',\n",
       " 'throughout',\n",
       " 'succeeds',\n",
       " 'sensibility',\n",
       " 'relief',\n",
       " 'casts',\n",
       " 'memorable',\n",
       " 'funniest',\n",
       " 'moving',\n",
       " 'mesmerizing',\n",
       " 'pitch-perfect',\n",
       " 'well-written',\n",
       " 'blockbuster',\n",
       " 'surefire',\n",
       " 'wallop',\n",
       " 'iconic',\n",
       " 'wedding',\n",
       " 'noteworthy',\n",
       " 'sobering',\n",
       " 'pleasantly',\n",
       " 'profundity',\n",
       " 'food-for-thought',\n",
       " 'wholly',\n",
       " 'captivates',\n",
       " 'convincing',\n",
       " 'thrillingly',\n",
       " 'valuable',\n",
       " 'rewarding',\n",
       " 'generous',\n",
       " 'environments',\n",
       " 'wonderfully',\n",
       " 'hilarious',\n",
       " 'ambition',\n",
       " 'spielberg',\n",
       " 'miracle',\n",
       " 'canny',\n",
       " 'first-rate',\n",
       " 'niche',\n",
       " 'foremost',\n",
       " 'effortlessly',\n",
       " 'impressive',\n",
       " 'dazzling',\n",
       " 'sheer',\n",
       " 'evocative',\n",
       " 'amazing',\n",
       " 'vivid',\n",
       " 'cute',\n",
       " 'celebrate',\n",
       " 'outstanding',\n",
       " 'beautiful',\n",
       " 'keen',\n",
       " 'escort',\n",
       " 'french',\n",
       " 'craft',\n",
       " 'enduring',\n",
       " 'gods',\n",
       " 'songs',\n",
       " 'flashes',\n",
       " 'rock-solid',\n",
       " 'enigmatic',\n",
       " 'top-notch',\n",
       " 'original',\n",
       " 'lightness',\n",
       " 'masterpiece',\n",
       " 'astronauts',\n",
       " 'pleasures',\n",
       " 'finesse',\n",
       " 'wonderful',\n",
       " 'played',\n",
       " 'advises',\n",
       " 'roles',\n",
       " 'pleasure',\n",
       " 'phenomenal',\n",
       " 'encourage',\n",
       " 'gut-wrenching',\n",
       " 'touching',\n",
       " 'honesty',\n",
       " 'faithful',\n",
       " 'success',\n",
       " 'medium',\n",
       " 'breathtaking',\n",
       " 'derrida',\n",
       " 'odyssey',\n",
       " 'sympathetic',\n",
       " 'careers',\n",
       " 'unique',\n",
       " 'compelling',\n",
       " 'kindness',\n",
       " 'gifted',\n",
       " 'trek',\n",
       " 'spectacular',\n",
       " 'visuals',\n",
       " 'grace',\n",
       " 'thrill',\n",
       " 'charmer',\n",
       " 'fresh',\n",
       " 'integrity',\n",
       " 'delivering',\n",
       " 'reefs',\n",
       " 'remarkably',\n",
       " 'stamina',\n",
       " 'comfort',\n",
       " 'sensual',\n",
       " 'presents',\n",
       " 'strong',\n",
       " 'landscapes',\n",
       " 'subtly',\n",
       " 'remarkable',\n",
       " 'inventive',\n",
       " 'career-defining',\n",
       " 'very',\n",
       " 'superb',\n",
       " 'bringing',\n",
       " 'infuses',\n",
       " 'self-discovery',\n",
       " 'coen',\n",
       " 'solid',\n",
       " 'captivating',\n",
       " 'stunning',\n",
       " 'shines',\n",
       " 'auspicious',\n",
       " 'principled',\n",
       " 'shining',\n",
       " 'glow',\n",
       " 'passion',\n",
       " 'sharp',\n",
       " 'lovely',\n",
       " 'satisfyingly',\n",
       " 'worth',\n",
       " 'comedic',\n",
       " 'vision',\n",
       " 'enables',\n",
       " 'propulsive',\n",
       " 'worthwhile',\n",
       " 'skill',\n",
       " 'fabulous',\n",
       " 'portrait',\n",
       " 'perceptiveness',\n",
       " 'grown-up',\n",
       " 'heartwarming',\n",
       " 'enthusiastic',\n",
       " 'pleasant',\n",
       " 'huston',\n",
       " 'sportsmen',\n",
       " 'wide',\n",
       " 'buoy',\n",
       " 'clooney',\n",
       " 'oomph',\n",
       " 'skills',\n",
       " 'stirring',\n",
       " 'twists',\n",
       " 'acclaimed',\n",
       " 'smartly',\n",
       " 'whale',\n",
       " 'challenging',\n",
       " 'assurance',\n",
       " 'elegant',\n",
       " 'won',\n",
       " 'delightful',\n",
       " 'venturesome',\n",
       " 'spare',\n",
       " 'exquisite',\n",
       " 'rare',\n",
       " 'pleasurable',\n",
       " 'celebration',\n",
       " 'craftsmen',\n",
       " 'comedy',\n",
       " 'talented',\n",
       " 'sparkles',\n",
       " 'devotion',\n",
       " 'intimate',\n",
       " 'joy',\n",
       " 'undeniable',\n",
       " 'constant',\n",
       " 'accomplish',\n",
       " 'true',\n",
       " 'delicious',\n",
       " 'excels',\n",
       " 'luscious',\n",
       " 'nominated',\n",
       " 'irresistible',\n",
       " 'affectionate',\n",
       " 'excellent',\n",
       " 'heart-wrenching',\n",
       " 'powerful',\n",
       " 'kidman',\n",
       " 'jolly',\n",
       " 'unpretentious',\n",
       " 'considerable',\n",
       " 'daring',\n",
       " 'enjoyable',\n",
       " 'winning',\n",
       " 'informative',\n",
       " 'breathtakingly',\n",
       " 'ably',\n",
       " 'greatest',\n",
       " 'articulate',\n",
       " 'gorgeous',\n",
       " 'souls',\n",
       " 'heart-warming',\n",
       " 'amiable',\n",
       " 'preciseness',\n",
       " 'affirming',\n",
       " 'catapulting',\n",
       " 'successful',\n",
       " 'epic',\n",
       " 'seeing',\n",
       " 'tender',\n",
       " 'delight',\n",
       " 'manner',\n",
       " 'deft',\n",
       " 'majestic',\n",
       " 'respect',\n",
       " 'sexy',\n",
       " 'hooks',\n",
       " 'grown-ups',\n",
       " 'passionate',\n",
       " 'skillful',\n",
       " 'champion',\n",
       " 'suitably',\n",
       " 'startling',\n",
       " 'fine',\n",
       " 'fire-breathing',\n",
       " 'perfectly',\n",
       " 'significance',\n",
       " 'explores',\n",
       " 'talent',\n",
       " 'brown',\n",
       " 'ahead',\n",
       " 'addressing',\n",
       " 'master',\n",
       " 'environment',\n",
       " 'real',\n",
       " 'delicate',\n",
       " 'demonstrates',\n",
       " 'alluring',\n",
       " 'bourne',\n",
       " 'fuzzy',\n",
       " 'high-end',\n",
       " 'bold',\n",
       " 'fascinating',\n",
       " 'efficiently',\n",
       " 'inspiration',\n",
       " 'reminds',\n",
       " 'moviegoing',\n",
       " 'greatness',\n",
       " 'heart',\n",
       " 'our',\n",
       " 'finely',\n",
       " 'impress',\n",
       " 'classic',\n",
       " 'treat',\n",
       " 'expressive',\n",
       " 'treasure',\n",
       " 'courage',\n",
       " 'confident',\n",
       " 'classy',\n",
       " 'authentic',\n",
       " 'achieving',\n",
       " 'graceful',\n",
       " 'great',\n",
       " 'spirit',\n",
       " 'luminous',\n",
       " 'ninth',\n",
       " 'consistency',\n",
       " 'son',\n",
       " 'touchstone',\n",
       " 'finest',\n",
       " 'timeless',\n",
       " 'cast',\n",
       " 'entertained',\n",
       " 'happiness',\n",
       " 'down-home',\n",
       " 'sets',\n",
       " 'pictures',\n",
       " 'believable',\n",
       " 'joyous',\n",
       " 'berry',\n",
       " 'bring',\n",
       " 'tenth',\n",
       " 'funky',\n",
       " 'shainberg',\n",
       " 'refreshing',\n",
       " 'elevates',\n",
       " 'postmodern',\n",
       " 'spirits',\n",
       " 'encouraging',\n",
       " 'vibrant',\n",
       " 'sensitive',\n",
       " 'uncommonly',\n",
       " 'holofcener',\n",
       " 'decisive',\n",
       " 'lane',\n",
       " 'devices',\n",
       " 'nachtwey',\n",
       " 'appealing',\n",
       " 'power',\n",
       " 'survival',\n",
       " 'understands',\n",
       " 'energetic',\n",
       " 'flawless',\n",
       " 'profound',\n",
       " 'freshness',\n",
       " 'embraces',\n",
       " 'chimes',\n",
       " 'timely',\n",
       " 'loving',\n",
       " 'illuminating',\n",
       " 'healing',\n",
       " 'bouquet',\n",
       " 'nature',\n",
       " 'captures',\n",
       " 'realistic',\n",
       " 'rollicking',\n",
       " 'romantic',\n",
       " 'rediscover',\n",
       " 'interesting',\n",
       " 'fontaine',\n",
       " 'sublime',\n",
       " 'behold',\n",
       " 'creative',\n",
       " 'masterful',\n",
       " 'talents',\n",
       " 'lovers',\n",
       " 'huppert',\n",
       " 'wondrously',\n",
       " 'likes',\n",
       " 'feature-length',\n",
       " 'action-packed',\n",
       " 'smart',\n",
       " 'rhythm',\n",
       " 'crisp',\n",
       " 'fantastic',\n",
       " 'philosophical',\n",
       " 'amicable',\n",
       " 'washington',\n",
       " 'reynolds',\n",
       " 'feast',\n",
       " 'witty',\n",
       " 'bouncy',\n",
       " 'gentle',\n",
       " 'honest',\n",
       " 'dream',\n",
       " 'artful',\n",
       " 'stuart',\n",
       " 'brave',\n",
       " 'bronze',\n",
       " 'establishes',\n",
       " 'intriguing',\n",
       " 'terrific',\n",
       " 'humor',\n",
       " 'directorial',\n",
       " 'good',\n",
       " 'marvelous',\n",
       " 'cat-and-mouse',\n",
       " 'adventurous',\n",
       " 'layered',\n",
       " 'most',\n",
       " 'accomplished',\n",
       " 'slickly',\n",
       " 'brightly',\n",
       " 'masterfully',\n",
       " 'listen',\n",
       " 'keeping',\n",
       " 'openness',\n",
       " 'flavorful',\n",
       " 'dazzle',\n",
       " 'propels',\n",
       " 'strength',\n",
       " 'richly',\n",
       " 'imax',\n",
       " 'definitely',\n",
       " 'melancholy',\n",
       " 'sly',\n",
       " 'satisfying',\n",
       " 'robust',\n",
       " 'super',\n",
       " 'wondrous',\n",
       " 'invaluable',\n",
       " 'warmth',\n",
       " 'ingenious',\n",
       " 'popcorn',\n",
       " 'sundance',\n",
       " 'refreshingly',\n",
       " 'delectable',\n",
       " 'irresistibly',\n",
       " 'flow',\n",
       " 'surprise',\n",
       " 'extraordinary',\n",
       " 'brilliant',\n",
       " 'immensely',\n",
       " 'backgrounds',\n",
       " 'choosing',\n",
       " 'stanley',\n",
       " 'tremendous',\n",
       " 'imaginative',\n",
       " 'generosity',\n",
       " 'thinkers',\n",
       " 'unforgettable',\n",
       " 'major-league',\n",
       " 'pellington',\n",
       " 'transforms',\n",
       " 'well-deserved',\n",
       " 'stylish',\n",
       " 'shine',\n",
       " 'serenity',\n",
       " 'graham',\n",
       " 'mix',\n",
       " 'loved',\n",
       " 'wholesome',\n",
       " 'energy',\n",
       " 'peace',\n",
       " 'marvelously']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex: superb brilliant perfectly excellent happiness happiness incredible outstanding tasteful\n",
    "\n",
    "list(set(positive_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### negative words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dissing',\n",
       " 'stealing',\n",
       " 'choppy',\n",
       " 'dragged',\n",
       " 'clichéd',\n",
       " 'puddle',\n",
       " 'intolerable',\n",
       " 'bolt',\n",
       " 'obscure',\n",
       " 'poor',\n",
       " 'irresponsible',\n",
       " 'insignificance',\n",
       " 'cheapo',\n",
       " 'copy',\n",
       " 'off-putting',\n",
       " 'haphazard',\n",
       " 'double-barreled',\n",
       " 'lifeless',\n",
       " 'inept',\n",
       " 'insulting',\n",
       " 'numbingly',\n",
       " 'lame',\n",
       " 'leash',\n",
       " 'parking',\n",
       " 'stupid',\n",
       " 'sordid',\n",
       " 'absurdly',\n",
       " 'atrociously',\n",
       " 'embarrassingly',\n",
       " 'garbage',\n",
       " 'schedule',\n",
       " 'undone',\n",
       " 'hypocritical',\n",
       " 'stinker',\n",
       " 'sociopathy',\n",
       " 'gang-raped',\n",
       " 'unfocused',\n",
       " 'substandard',\n",
       " 'cheesier',\n",
       " 'ailments',\n",
       " 'horribly',\n",
       " 'maudlin',\n",
       " 'untalented',\n",
       " 'ineffective',\n",
       " 'pileup',\n",
       " 'deficit',\n",
       " 'insultingly',\n",
       " 'pit',\n",
       " 'unmotivated',\n",
       " 'sluggish',\n",
       " 'malaise',\n",
       " 'irritating',\n",
       " 'shriveled',\n",
       " 'sentence',\n",
       " 'lackluster',\n",
       " 'bleak',\n",
       " 'vague',\n",
       " 'bogus',\n",
       " 'distanced',\n",
       " 'mistake',\n",
       " 'waste',\n",
       " 'shapeless',\n",
       " 'foul-mouthed',\n",
       " 'ludicrous',\n",
       " 'sabotaged',\n",
       " 'sickening',\n",
       " 'embarrassment',\n",
       " 'toilet',\n",
       " 'laziness',\n",
       " 'inevitable',\n",
       " 'wimps',\n",
       " 'overplayed',\n",
       " 'questionable',\n",
       " 'distasteful',\n",
       " 'preposterous',\n",
       " 'insufferable',\n",
       " 'mawkish',\n",
       " 'piss',\n",
       " 'milquetoast',\n",
       " 'exaggeration',\n",
       " 'smeary',\n",
       " 'hack',\n",
       " 'remotely',\n",
       " 'deathly',\n",
       " 'porridge',\n",
       " 'unattractive',\n",
       " 'hole',\n",
       " 'fudged',\n",
       " 'preachy',\n",
       " 'unimaginatively',\n",
       " 'numbing',\n",
       " 'sour',\n",
       " 'obnoxiously',\n",
       " 'impersonal',\n",
       " 'hangover',\n",
       " 'staring',\n",
       " 'insufferably',\n",
       " 'overwritten',\n",
       " 'choppiness',\n",
       " 'paper-thin',\n",
       " 'squabbling',\n",
       " 'junk',\n",
       " 'bilked',\n",
       " 'awkward',\n",
       " 'unclean',\n",
       " 'flat',\n",
       " 'loose',\n",
       " 'listless',\n",
       " 'bloated',\n",
       " 'clunky',\n",
       " 'marred',\n",
       " 'needlessly',\n",
       " 'inauthentic',\n",
       " 'exasperated',\n",
       " 'shallow',\n",
       " 'arbitrary',\n",
       " 'abrupt',\n",
       " 'lousy',\n",
       " 'lapses',\n",
       " 'foolish',\n",
       " 'implausible',\n",
       " 'unexplained',\n",
       " 'delinquent',\n",
       " 'suffers',\n",
       " 'boring',\n",
       " 'thrown',\n",
       " 'delay',\n",
       " 'flimsy',\n",
       " 'miserable',\n",
       " '15-year',\n",
       " 'cobbled',\n",
       " 'worse',\n",
       " 'incoherence',\n",
       " 'tolerate',\n",
       " 'disappointments',\n",
       " 'crummy',\n",
       " 'inadvertent',\n",
       " 'woefully',\n",
       " 'ripoff',\n",
       " 'stubbornly',\n",
       " 'excruciating',\n",
       " 'ransacked',\n",
       " 'limp',\n",
       " 'repetitive',\n",
       " 'let-down',\n",
       " 'gimmicky',\n",
       " 'badly',\n",
       " 'venality',\n",
       " 'excesses',\n",
       " 'disaster',\n",
       " 'unfulfilling',\n",
       " 'astray',\n",
       " 'illogical',\n",
       " 'tired',\n",
       " 'irrelevant',\n",
       " 'tacky',\n",
       " 'overdone',\n",
       " 'dud',\n",
       " 'flatulence',\n",
       " 'indifferent',\n",
       " 'dreck',\n",
       " 'phony',\n",
       " 'amateurish',\n",
       " 'muddled',\n",
       " 'witless',\n",
       " 'cracked',\n",
       " 'stiff',\n",
       " 'thinly',\n",
       " 'fussy',\n",
       " 'one-sided',\n",
       " 'stumbles',\n",
       " 'vapid',\n",
       " 'bore',\n",
       " 'worthless',\n",
       " 'shrug',\n",
       " 'sloppily',\n",
       " 'moronic',\n",
       " 'italicized',\n",
       " 'irreparable',\n",
       " 'insults',\n",
       " 'hastily',\n",
       " 'distressingly',\n",
       " 'sloppiness',\n",
       " 'drowned',\n",
       " 'letdown',\n",
       " 'doze',\n",
       " 'monotonous',\n",
       " 'bored',\n",
       " 'puerile',\n",
       " 'worn-out',\n",
       " 'soggy',\n",
       " 'sappy',\n",
       " 'pawn',\n",
       " 'split',\n",
       " 'ugly',\n",
       " 'afterthought',\n",
       " 'whining',\n",
       " 'pocket',\n",
       " 'lameness',\n",
       " 'moat',\n",
       " 'sputters',\n",
       " 'bitter',\n",
       " 'disappointingly',\n",
       " 'annoyed',\n",
       " 'unnecessary',\n",
       " 'idiotic',\n",
       " 'worst',\n",
       " 'tiresome',\n",
       " 'unconvincing',\n",
       " 'impassive',\n",
       " 'depressing',\n",
       " 'pointless',\n",
       " 'poorly',\n",
       " 'disposable',\n",
       " 'britney',\n",
       " 'unfunny',\n",
       " 'hideously',\n",
       " 'redundancies',\n",
       " 'disintegrating',\n",
       " 'bitten',\n",
       " 'redundant',\n",
       " 'flop',\n",
       " 'cheapened',\n",
       " 'rehash',\n",
       " 'mess',\n",
       " 'undercut',\n",
       " 'unsympathetic',\n",
       " 'insult',\n",
       " 'undermined',\n",
       " 'rigidly',\n",
       " 'awkwardly',\n",
       " 'surrender',\n",
       " 'bother',\n",
       " 'stale']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex: unlikable lifeless poorly pointless stupid absurdly distasteful garbage sexist trash\n",
    "\n",
    "list(set(negative_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation-based explanation (leave-one-out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach have been presented by (Wallace et al., 2020) in their tutorial. It is a simple method that defines the importance as a drop in prediction when the feature is removed. The approach is described in the following image from Wallace et al. 'S tutorial slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/leave_one_out.PNG\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hohman et al.'s human-centered interrogative framework**:\n",
    "\n",
    "    - Why:\n",
    "        - Interpretability and explainability\n",
    "        - Detecting bias in the dataset/model\n",
    "\n",
    "    - What:\n",
    "        - The model's prediction score\n",
    "\n",
    "    - When:\n",
    "        - After training\n",
    "\n",
    "    - Who:\n",
    "        - Model developers\n",
    "        - Model Users\n",
    "        - Non-experts\n",
    "\n",
    "    - How:\n",
    "        - Visualize feature importance using saliency maps\n",
    "        \n",
    "    - Where:\n",
    "        - Application domains        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_each_word(text: str, model: nn.Module=model):\n",
    "    \n",
    "    x, _ = transform_text(text)\n",
    "    \n",
    "    score_text, _ = predict(x, model)\n",
    "    \n",
    "    var = []\n",
    "    \n",
    "    tokens = text.split()\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "                \n",
    "        var.append((tokens[i], ' '.join([w for (k, w) in enumerate(tokens) if k!=i])))\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for pairs in var:\n",
    "        \n",
    "        x, _ = transform_text(pairs[1])\n",
    "        \n",
    "        score_w, _ = predict(x, model)\n",
    "        \n",
    "        sc = score_text - score_w\n",
    "        \n",
    "        scores.append((pairs[0], sc))\n",
    "        \n",
    "    return scores, score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact(text='the movie is not bad')\n",
    "def explain_by_perturbation(text: str):\n",
    "    \n",
    "    model.cpu()\n",
    "    model.eval() # eval mode\n",
    "    \n",
    "    scores, score_text = score_each_word(text, model)\n",
    "    \n",
    "    if score_text > 0.5:\n",
    "        print(f'positive => {score_text: 0.3f}')\n",
    "    \n",
    "    else:\n",
    "        print(f'negative => {score_text: 0.3f}')\n",
    "    \n",
    "    arr = np.array(\n",
    "        [el[1] for el in scores]\n",
    "    ).reshape(1, -1)\n",
    "\n",
    "    y = [el[0] for el in scores]\n",
    "    \n",
    "    heatmap = pd.DataFrame(data = arr, columns=y)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "\n",
    "    sns.heatmap(heatmap, annot=True, yticklabels=False, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative =>  0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAACQCAYAAABqMRpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYlklEQVR4nO3de5xd47348c93ZhIJEkmQiKCIpISmURFKlCJa1ImWqjatUJWiLqfnFw6iFMerLr+WnpboiEuoupNEG5eIurVU4pKQoFEJkgZNSBBUkzznj71MJ7N3zIw9mTWz83m/Xuu11+VZz/qu5Hnt2d/1PGutSCkhSZIkSZLyU5V3AJIkSZIkre1MziVJkiRJypnJuSRJkiRJOTM5lyRJkiQpZybnkiRJkiTlzORckiRJkqScmZxLkiRJklRPRHw1Il6MiJci4rQS29eJiJuz7X+JiC3LPabJuSRJkiRJmYioBi4D9gcGAN+OiAENih0NvJ1S2ga4BLiw3OOanEuSJEmS9G9DgJdSSi+nlD4CbgKGNygzHBifzd8G7BMRUc5BTc4lSZIkSfq3PsBr9ZbnZ+tKlkkpLQeWAhuWc9CaT9p4bHRN5VQuSZJU3xXLXmu8kNQOHLve5nmHILWIK9I7ZfX2tnWlctrf8O4PgVH1VtWmlGrrLZf6N2lYT1PKNMsnJueSJEmSJLVXNSVGmqeVqRaoLS5dZz5Q/wrcZsDfV1NmfkTUABsAb5UTq8PaJUmSJEkVqSaKpyaYBvSLiK0ioiNwODCpQZlJwMhs/lDggZSSPeeSJEmSJDVUque8MSml5RFxAnAvUA1cnVKaFRHnAtNTSpOAq4DrI+IlCj3mh5cda7kVSJIkSZLUFnX8lHfUp5QmA5MbrDur3vyHwDfLia0hk3NJkiRJUkWqLu/tZq3K5FySJEmSVJGaeI95m2ByLkmSJEmqSB2r2k92bnIuSZIkSapINSVfR942mZxLkiRJkipSx3b08nCTc0mSJElSRfo0r1LLi8m5JEmSJKki+UA4SZIkSZJy1sGec0mSJEmS8uWwdkmSJEmScuawdkmSJEmScmbPuSRJkiRJOWtHb1IzOZckSZIkVaaqdtRz3p4uJEiSJEmS1GQ1EUVTOSKiR0RMiYg52Wf3EmUGRcRjETErImZGxLeaUrfJuSRJkiSpIlWVmMp0GjA1pdQPmJotN/Q+cERKaXvgq8ClEdGtKbFKkiRJklRxqiOKpjINB8Zn8+OBgxsWSCn9NaU0J5v/O/AmsHFjFXvPuSRJkiSpIlW3/C3nvVJKCwFSSgsjoucnFY6IIUBH4G+NVWxyLkmSJEmqSNUUZ+cRMQoYVW9VbUqptt72+4FNSlQ3pjnHjojewPXAyJTSysbKm5xLkiRJkipSVYme8ywRry3eUrd939Vti4g3IqJ31mvem8KQ9VLlugJ/AM5MKT3epFibUkiSJEmSpPampZ/WDkwCRmbzI4GJDQtEREfgTuC6lNKtTa3Y5FySJEmSVJGqiKKpTBcAwyJiDjAsWyYiBkfEuKzMYcCXgCMj4plsGtRYxQ5rlyRJkiRVpJoWfiBcSmkxsE+J9dOBH2TzvwV+29y6Tc4lSZIkSRWpqvxh7K3G5FySJEmSVJFMziVJkiRJyllNS49rX4NMziVJkiRJFamq1LvU2iiTc0mSJElSRTI5lyRJkiQpZzXVJueSJEmSJOWqyuRckiRJkqR8OaxdkiRJkqSc1VRX5R1Ck5mcS5IkSZIqkj3nkiRJkiTlrKr9dJybnEuSJEmSKlNNTfvJzk3OJUmSJEkVqT0Na28/lxEkSZIkSWqG6uoomsoRET0iYkpEzMk+u39C2a4RsSAift2Uuk3OJUmSJEkVqao6iqYynQZMTSn1A6Zmy6tzHvBQUys2OZckSZIkVaSoriqayjQcGJ/NjwcOLnnciJ2AXsB9Ta3Y5FySJEmSVJGiprpoKlOvlNJCgOyzZ9ExI6qAnwOnNKdiHwgnSZIkSapIpXrKI2IUMKreqtqUUm297fcDm5SobkwTD3s8MDml9FpE04fRm5xLkiRJkipSqeQ8S8Rri0vXbd93tfVFvBERvVNKCyOiN/BmiWJfBPaIiOOB9YGOEfFeSumT7k83OZckSZIkVaYWGMbe0CRgJHBB9jmxYYGU0oi640ccCQxuLDEH7zmXJEmSJFWq6qriqTwXAMMiYg4wLFsmIgZHxLhyKrbnXJIkSZJUkaL8V6etIqW0GNinxPrpwA9KrL8WuLYpdZucS5IkSZIqUnRo8WHta4zJeRnOn/ssH777HitXrGDl8uX8bOe9Vtnef8+hHDfxRhbNfQWAp++4i8nnXdisY3zltP9i96OPYOWKFdxy0qnMvm9qk44tNYdtWZUiqqo4ffpDLFmwkMsPOqxo+07f/Dpf++nppJSYP+M5rh5xdLPqP+yXF7HDAfvx0fvvM/7I43jt6RkAXL78bRY8OwuAt16dz9jhh5d/MtKn9Le58zjj7HOZ9cKL/PiE4zj6iO/mHZIEQOcNNuB7437FpjsMIKXEdd//EXMff6JJ+27xhUGMvHYsHTp35rnJ93HLyacC8LWzT2foMSN59x+LAJh4xrk8d3eTXyuttUALvNe81Zicl+kXXz6QZYvfWu32OY88VvIHYlP03u6z7Hz4IZy7/RA22LQ3/3n/JM7qvyNp5comHVtqDtuyKsHeJx/H68//lU5duxRt67lNX75y+n9x8e778f6SJXTZeKNm1b3D/vvRs19fzuo3iK122ZnvjL2EC3fdG4CPPviA83cc2iLnIJWr2wZdGfPfo5n6xwfzDkVaxWG/vJBZ99xP7TePoLpDBzquu26T9/3O2Ev47aiTmfv4E5ww+Xa2/+owZt0zBYCpl1zGlJ//ak2FrXYuqtpPct5+Iq0wQ0Z8i9P+8kfGPP0o37ni0pKNZuDwA5l20+0s/+gjFs97hTdfepkthwzOIVpp9WzLaiu69dmUzx34Ff40bnzJ7UOPGclDl13J+0uWANT1sgAMG30Spz3xIGfO+DNf++kZJfcfOPwAHr/uRgDm/mUanbttQNdNerXwWUjl27BHDwZuP4CaGvtg1HZ06tKFfl/ajT9ddR0AK/71Lz5YupSNtt6KE+++g9OnP8T/e/geen22X9G+XTfpRaeuXep62R+/7kY+f/CBrRq/2q/oUF00tVUm52VIKXHyfRM4ffpDDD3myJJltv7iEM585k+cMPl2eg/YFoBNtu3P4G99g4t2H8b5Ow4lrVjJkBHfKtq3e59Nefu1BXXLS+YvoHuf3k0+ttRUtmVVgsMuvYA7Tj2rbkRGQz37b0Ov/ttwyqP3cepjUxnwlcIrTLcbtjc9+/XlgiF7cf6g3dlip0Fss8duRft367Mpb782v255yfwFdOuzKQAdOnXi9GkPcupjU/n8cH8wSlJDG229Je/9YzEjrxnLGU89wnev/BUd112X79b+kptPPIWfDd6T20efybcv/0XRvt36bMrb81f9HfHx9y/AXieM4swZf+Z7V13Gut26tcr5qP2I6qqiqa3ykmoZLt59P5YufJ0uG2/EyVMm8voLf+WlR/5ct/3Vp2Yw5jPb889ly9hh//04bsKNnNV/R7bdZy+22GkQp097EIAOnTvz7pv/KD5AFD9ZMKXUpGNLzWFbVnv3uQO/yrtvLuLVp56h/56lh5dX1dTQs19ffr7XAXTfrA+jH7mHc3fYlQH77c2A/fZmzNOPArDO+uvTs1/fonYYJdoxWTs+Y4sBLF34OhtttSU/fuAuFjw7m0Uvz23Rc5Sk9qyqpobNv/B5bjrxFOY9MZ3DLr2Q4f/zE7bebReOufXfI55q1lmnaN9P+v59aOw4/nDehZAS/3HemRzy8/O5/ugfrbHzUDvUhpPxhkzOy7B04etAYWjkM3f+nq2G7LTKj7kP3323bv65u+/j25f/nPU27AERPD7+d0w445xV6ht08Nc48OzCu+mv/8GJvD1/Ad0371O3vdtmfVjy99ebdGypOWzLau/67r4LA/9jf3Y4YBg1nTrRuWsXjrr+Sq753jF1ZZbMX8Dcx6excvlyFs97hTdenEPPfn0hgnt+9gseqb1mlTr3PP4Yhh4zEoBfH3Bo1o43q9teaMcLgX+340Vz5/HXBx9lix0HmpyrVd1w863ccscEAGp/dSm9em6cc0TSqpbMX8CS+QuY98R0AJ66bQIHnTuGD5YsLXpmR1RVccaTDwMwc9LdPDR2HN03a/g7ovD9W79T4NErx3P8729Z06eidiZq2u4w9obaz2WENqbjuuuyzvrr181vt9/eLHju+VXKdO3Vs25+y513IqqqWLb4LV6c+iBfOPTguocRrdu9Oz222JxnJvye83ccyvk7DuXVJ59m5qTJ7Hz4IdR07MiGW36Gnv22Zt4T05t0bKmpbMuqBBPOOIfTN9+OMVt9jqsOP4oXHnh4lcQc4JkJf6D/l78EwHob9qBn/21Y9PI8Zt87ld2+/z3WWW89ALpt2psuG2/EQ5dfWdeOly58nZmT7mbXI74NwFa77MyHS9/hndffYN1u3ajp2LGu3r6778rC2S+04tlLMOJb32TizTcw8eYbTMzVJr3zxpu89doCevXfBoBt99mLV6Y/zaK5r/CFQw+uK9dn4A6klSvrvn/vOvt83nn9DT589z222mVnAHY94tvMnDgZYJVnfwz6+kH83d8Raqiqqnhqo+w5/5S69urJsXfeABSG6Uz73a3Mvvd+9vjh9wF45DdX84VDD+ZLxx3NyuXL+eiDDxl3+FEALHz+RSaeeR4n3TeBqKpixb/+xU0/Gs1br762yjEWzn6BJ2+5k7NnT2PF8uXc9KPRpJUrV3ts6dOwLauSHXTOGF6Z/hQz77qb2ffez4D99ubsWU+wcsUK7jjlJyx76y2en/IAvbf7LKc+Vmh7/3xvGVd/95hVHhgH8Nzke9nhgP0476UZhVepHXU8AJts158Rv/klaeVKoqqKey74BQuff7HVz1X62D8WLeKQEUfy3rJlVEUw/oabmHz7TayfXQyV8nLziafw/RvGUd2xI4tensd1Rx1P524b8J2xl3DAmadQ3aED0266nQUznyva93fH/ZiR146lY+fOzLp7St3r0r5x0XlsPuhzpJRYPO9Vbvjhya19Wmrr2tHDMePj+z5LOTa6rn6jJElSM12x7LXGC0ntwLHrbZ53CFKLuCK9U+Km/sqx/NTDinLamotuaZPn3H4uI0iSJEmS1BxteBh7QybnkiRJkqTK1I6GtbefywiSJEmSJDVHCz8QLiJ6RMSUiJiTfXZfTbktIuK+iHg+ImZHxJaNhlpWZJIkSZIktVFRXV00lek0YGpKqR8wNVsu5Trg4pTSdsAQ4M3GKjY5lyRJkiRVppqa4qk8w4Hx2fx44OCGBSJiAFCTUpoCkFJ6L6X0fmMVm5xLkiRJkipTy7/nvFdKaSFA9tmzRJn+wJKIuCMino6IiyOi0S779nN3vCRJkiRJzVFiGHtEjAJG1VtVm1Kqrbf9fmCTErWNaeJRa4A9gB2BV4GbgSOBqxrbSZIkSZKkylNiGHuWiNcWF67bvu/qtkXEGxHRO6W0MCJ6U/pe8vnA0ymll7N9JgC70khy7rB2SZIkSVJlavlh7ZOAkdn8SGBiiTLTgO4RsXG2vDcwu9FQy41MkiRJkqQ2qbq6eCrPBcCwiJgDDMuWiYjBETEOIKW0AhgNTI2IZ4EArmysYoe1S5IkSZIqU3XLprwppcXAPiXWTwd+UG95CjCwOXWbnEuSJEmSKlP5PeWtxuRckiRJklSZTM4lSZIkScpZCw9rX5PaT6SSJEmSJDWHPeeSJEmSJOWspkPeETSZybkkSZIkqTJV2XMuSZIkSVK+qqvyjqDJTM4lSZIkSZXJYe2SJEmSJOXMYe2SJEmSJOXMp7VLkiRJkpSzmvaT8rafSCVJkiRJag6HtUuSJEmSlLN2NKy9/TxXXpIkSZKk5qjuUDyVISJ6RMSUiJiTfXZfTbmLImJWRDwfEf8bEdFY3SbnkiRJkqTKVF1dPJXnNGBqSqkfMDVbXkVE7AbsDgwEdgB2BvZsrGKTc0mSJElSZaqqLp7KMxwYn82PBw4uUSYBnYCOwDpAB+CNxir2nnNJkiRJUkWKMoexl9ArpbQQIKW0MCJ6NiyQUnosIv4ILAQC+HVK6fnGKjY5lyRJkiRVphLD2CNiFDCq3qralFJtve33A5uUqG1MUw4ZEdsA2wGbZaumRMSXUkoPf9J+JueSJEmSpMpUXZzyZol4bXHhuu37rm5bRLwREb2zXvPewJslin0deDyl9F62z93ArsAnJufecy5JkiRJqkwt/0C4ScDIbH4kMLFEmVeBPSOiJiI6UHgYXKPD2k3OJUmSJEmVqeUfCHcBMCwi5gDDsmUiYnBEjMvK3Ab8DXgWmAHMSCnd1VjFDmuXJEmSJFWmFn4gXEppMbBPifXTgR9k8yuAHza3bpNzSZIkSVJFivKHsbcak3NJkiRJUmUqfxh7qzE5lyRJkiRVppoWf8/5GmNyLkmSJEmqTPacS5IkSZKUs2g/LygzOZckSZIkVSZ7ziVJkiRJyllV5B1Bk5mcS5IkSZIqk8PaJUmSJEnKmcPaJUmSJEnKmT3nkiRJkiTlzORckiRJkqR8hcPaJUmSJEnKWZU955IkSZIk5cvkXJIkSZKknHnPuSRJkiRJOTM5lyRJkiQpZ+3ogXCRUso7hrVaRIxKKdXmHYdULtuyKoVtWZXAdqxKYVvW2qT99PFXrlF5ByC1ENuyKoVtWZXAdqxKYVvWWsPkXJIkSZKknJmcS5IkSZKUM5Pz/HkPjSqFbVmVwrasSmA7VqWwLWut4QPhJEmSJEnKmT3nkiRJkiTlzOS8FUREt4g4PpvfKyJ+n3dMUmuKiGMj4oi845CktVlEHBkRm+Ydh9TSImLLiHgu7zikcpmct45uwPF5ByHlJaV0RUrpurzjkKS13JGAybkktVEm563jAqBvRDwDXAysHxG3RcQLEXFDRARAROwUEQ9FxJMRcW9E9M41aq2VsqvPL0TEuIh4Lmuj+0bEnyJiTkQMiYgeETEhImZGxOMRMTAiqiJiXkR0q1fXSxHRKyJ+GhGjs3V9I+KerJ0/EhHb5ne2WptExKkRcVI2f0lEPJDN7xMRv42IsRExPSJmRcQ59fa7ICJmZ+39/+cVv9RQ9n39fERcmbXb+yKic0QMyr6bZ0bEnRHRPSIOBQYDN0TEMxHROe/4tfaKiJ9kvzWmRMSNETG6VLvNyq5u/U4RMSMiHgN+lOsJSS3E5Lx1nAb8LaU0CDgF2BH4T2AAsDWwe0R0AH4FHJpS2gm4Gjg/p3ilbYBfAgOBbYHvAEOB0cAZwDnA0ymlgdnydSmllcBE4OsAEbELMC+l9EaDumuBE7N2Phq4fM2fjgTAw8Ae2fxgChdKO1Bo248AY1JKgym0+z2zi049KLTp7bP2/j85xC19kn7AZSml7YElwCHAdcB/Z232WeDslNJtwHRgREppUErpg9wi1lotIgZTaKc7At+g8H0MJdptI+uvAU5KKX2xtWKX1rSavANYSz2RUpoPkPWmb0nhD+oOwJSsI70aWJhXgFrrzU0pPQsQEbOAqSmlFBHPUmivn6Hwh5WU0gMRsWFEbADcDJxF4Q/m4dlynYhYH9gNuDVr5wDrrPnTkQB4EtgpIroA/wSeovCjcA/gJOCwiBhF4W9jbwoXUGcDHwLjIuIPgM8MUVszN6X0TDb/JNAX6JZSeihbNx64NZfIpNKGAhM/vkAUEXcB61Gi3Wa/LZqy/npg/1Y7A2kNMTnPxz/rza+g8P8QwCyv/qmNqN9GV9ZbXkmhvS4vsU8CHgO2iYiNgYMp7mWsApZko0ikVpVS+ldEzAOOAv4MzAS+TCGZ+YDCSI6dU0pvR8S1QKeU0vKIGALsQ+GC0wnA3jmEL61Ow98U3VZXUGojovEiTarD90Gr4jisvXW8C3RppMyLwMYR8UWAiOgQEduv8cikT+dhYAQU3kAALEopvZNSSsCdwC+A51NKi+vvlFJ6B5gbEd/M9o2I+HyrRq613cMUkvCHKQxlPxZ4BugKLAOWRkQvsh6YbLTHBimlyRRuR/LCktq6pcDbEfHxLRzfAz7uXWzK7xFpTXsUOCgiOmXfsQdS+P4tarcppZLtOaW0hML39dBs/YhWjF9aY+w5bwUppcXZw7Seo9A70/AeXFJKH2UPa/nfbKhODXApMKt1o5Wa5KfANRExE3gfGFlv283ANApPBS5lBDA2Is4EOgA3ATPWWKTSqh4BxgCPpZSWRcSHwCMppRkR8TSF79yXgT9l5bsAEyOiE4Wemh/nEbTUTCOBKyJiXQrt+ahs/bXZ+g+AL3rfufKQUpoWEZMo/O1/hcKzEJay+na7uvVHAVdHxPvAva14CtIaE4WOLkmSJEla8yJi/ZTSe1nC/TAwKqX0VN5xSXmz51ySJElSa6qNiAFAJ2C8iblUYM+5JEmSJEk584FwkiRJkiTlzORckiRJkqScmZxLkiRJkpQzk3NJkiRJknJmci5JkiRJUs5MziVJkiRJytn/AVB7qHkkBsr8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_by_perturbation('the movie was not good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach estimate the importance of a word by using the derivative of the output with respect to the embedding of that word. In our experiment, we compute the L2 norm of this gradient to obtain the word importance but better approaches are available in the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hohman et al.'s human-centered interrogative framework**:\n",
    "\n",
    "    - Why:\n",
    "        - Interpretability and explainability\n",
    "        - Detecting bias in the dataset/model\n",
    "\n",
    "    - What:\n",
    "        - There L2 norm of the gradient output with respect to the inputs (word embedding)\n",
    "\n",
    "    - When:\n",
    "        - After training\n",
    "\n",
    "    - Who:\n",
    "        - Model developers\n",
    "        - Model Users\n",
    "        - Non-experts\n",
    "\n",
    "    - How:\n",
    "        - Visualize feature importance using saliency maps\n",
    "\n",
    "    - Where:\n",
    "        - Application domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_grad(x: torch.LongTensor, model: nn.Module=model):\n",
    "    \n",
    "    embed_grad = []\n",
    "    \n",
    "    def grad_hook(module, grad_in, grad_out):\n",
    "        embed_grad.append(grad_out[0].squeeze())\n",
    "        \n",
    "    embedding_layer = model.encode.embedding\n",
    "    \n",
    "    handle = embedding_layer.register_backward_hook(grad_hook)\n",
    "        \n",
    "    y, *_ = model(x)\n",
    "    \n",
    "    y.backward()\n",
    "    \n",
    "    handle.remove()\n",
    "        \n",
    "    grad_norm = embed_grad[0].norm(2, dim=1)    \n",
    "    \n",
    "    if y.item() > 0.5:\n",
    "        print(f'positive => {y.item(): 0.3f}')\n",
    "    \n",
    "    else:\n",
    "        print(f'negative => {y.item(): 0.3f}')\n",
    "        \n",
    "    return grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@interact(text='the movie is not bad')\n",
    "def explain_with_gradient(text: str):\n",
    "    \n",
    "    model.cpu()\n",
    "    model.eval() # eval mode\n",
    "    \n",
    "    sequence = sent2ids(text.lower()) # convert to ids\n",
    "    \n",
    "    seq_torch, word_sequence = transform_text(text)\n",
    "    \n",
    "    normalized_grad_norm = get_emb_grad(seq_torch, model).numpy()\n",
    "    \n",
    "    heatmap = pd.DataFrame(data =  normalized_grad_norm.reshape(1, -1), columns=word_sequence)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    \n",
    "    sns.heatmap(heatmap, annot=True, yticklabels=False, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative =>  0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explain_with_gradient('this is a bad movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **EMNLP 2020 Tutorial** on Interpreting Predictions of NLP Models (Eric Wallace, Matt Gardner, Sameer Singh)\n",
    "    * https://www.youtube.com/watch?v=gprIzglUW1s&t=3384s \n",
    "* **NeurIPS 2020 Tutorial** on Explaining ML Predictions: State-of-the-art, Challenges, and Opportunities (Himabindu Lakkaraju, Julius Adebayo, Sameer Singh)\n",
    "    * https://www.youtube.com/watch?v=EbpU4p_0hes&t=6900s\n",
    "* A Survey of the State of Explainable AI for Natural Language Processing (Danilevsky et al., 2020)\n",
    "* A Diagnostic Study of Explainability Techniques for Text Classification (Atanasova et al., 2020)\n",
    "* Attention is not explanation (Jain and Wallace, 2019)\n",
    "* Attention is not not explanation (Wiegreffe and Pinter, 2019)\n",
    "* Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et al., 2015)\n",
    "* Attention Is All You Need (Vaswani et al., 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
